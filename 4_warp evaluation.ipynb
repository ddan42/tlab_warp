{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport copy\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n\nfrom datasets import Dataset, load_dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-05T12:19:51.442261Z","iopub.execute_input":"2024-08-05T12:19:51.443096Z","iopub.status.idle":"2024-08-05T12:19:58.499546Z","shell.execute_reply.started":"2024-08-05T12:19:51.443059Z","shell.execute_reply":"2024-08-05T12:19:58.498460Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# basic random seed\nimport os \nimport random\n\nDEFAULT_RANDOM_SEED = 42\n\ndef seedBasic(seed=DEFAULT_RANDOM_SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \ndef seedTorch(seed=DEFAULT_RANDOM_SEED):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \ndef seedEverything(seed=DEFAULT_RANDOM_SEED):\n    seedBasic(seed)\n    seedTorch(seed)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:19:58.500993Z","iopub.execute_input":"2024-08-05T12:19:58.501447Z","iopub.status.idle":"2024-08-05T12:19:58.507884Z","shell.execute_reply.started":"2024-08-05T12:19:58.501420Z","shell.execute_reply":"2024-08-05T12:19:58.506987Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:19:58.509073Z","iopub.execute_input":"2024-08-05T12:19:58.509386Z","iopub.status.idle":"2024-08-05T12:19:58.517663Z","shell.execute_reply.started":"2024-08-05T12:19:58.509361Z","shell.execute_reply":"2024-08-05T12:19:58.516793Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:19:58.520075Z","iopub.execute_input":"2024-08-05T12:19:58.520380Z","iopub.status.idle":"2024-08-05T12:19:58.555443Z","shell.execute_reply.started":"2024-08-05T12:19:58.520351Z","shell.execute_reply":"2024-08-05T12:19:58.554636Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_parquet('/kaggle/input/imdb-csv/Test Data.parquet')","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:19:58.556605Z","iopub.execute_input":"2024-08-05T12:19:58.556932Z","iopub.status.idle":"2024-08-05T12:19:58.981748Z","shell.execute_reply.started":"2024-08-05T12:19:58.556901Z","shell.execute_reply":"2024-08-05T12:19:58.980722Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"test_df = test_df[test_df['label'] == 1].reset_index(drop=True)\ntest_df = test_df[:100]\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:19:58.983088Z","iopub.execute_input":"2024-08-05T12:19:58.983434Z","iopub.status.idle":"2024-08-05T12:19:59.007993Z","shell.execute_reply.started":"2024-08-05T12:19:58.983408Z","shell.execute_reply":"2024-08-05T12:19:59.007193Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0  Previous reviewer Claudio Carvalho gave a much...      1\n1  CONTAINS \"SPOILER\" INFORMATION. Watch this dir...      1\n2  This is my first Deepa Mehta film. I saw the f...      1\n3  This was a great film in every sense of the wo...      1\n4  A stunningly well-made film, with exceptional ...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Previous reviewer Claudio Carvalho gave a much...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CONTAINS \"SPOILER\" INFORMATION. Watch this dir...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This is my first Deepa Mehta film. I saw the f...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This was a great film in every sense of the wo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A stunningly well-made film, with exceptional ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"policy_tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/gpt2-imdb\")\nsft_model = AutoModelForCausalLM.from_pretrained(\"lvwerra/gpt2-imdb\")\n\nsft_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:19:59.009464Z","iopub.execute_input":"2024-08-05T12:19:59.010107Z","iopub.status.idle":"2024-08-05T12:20:04.873702Z","shell.execute_reply.started":"2024-08-05T12:19:59.010070Z","shell.execute_reply":"2024-08-05T12:20:04.872647Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69ef81f3f9444e3e845d06526b629c05"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/577 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95121446bfdc4b3ca0606f6b75c96db6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbd0966fade84390bfe1e386c42e4e13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5297ade354754819a968871fd19bdc10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e2b735609c74e7cb383f9112d71998a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8893bb5ba5cb453895b0b016dcf5c49a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"reward_model_path = '/kaggle/input/reward2-0/distilbert-imdb/'\n\nreward_tokenizer = AutoTokenizer.from_pretrained(reward_model_path, local_files_only = True)\nreward_model = AutoModelForSequenceClassification.from_pretrained(reward_model_path, local_files_only = True)\n\nreward_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:04.875003Z","iopub.execute_input":"2024-08-05T12:20:04.875406Z","iopub.status.idle":"2024-08-05T12:20:06.799113Z","shell.execute_reply.started":"2024-08-05T12:20:04.875363Z","shell.execute_reply":"2024-08-05T12:20:06.798110Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"first_n = 10\n# leave first n and tokenize text and create a dataloader\ntokenized = policy_tokenizer(test_df['text'].tolist())\ntokenized = [x[:first_n] for x in tokenized['input_ids']]\ntokenized = torch.IntTensor(tokenized)\ntokenized = tokenized.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:06.800445Z","iopub.execute_input":"2024-08-05T12:20:06.801471Z","iopub.status.idle":"2024-08-05T12:20:06.868326Z","shell.execute_reply.started":"2024-08-05T12:20:06.801432Z","shell.execute_reply":"2024-08-05T12:20:06.866639Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1160 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"warp_model = AutoModelForCausalLM.from_pretrained('/kaggle/input/warp2-0/', local_files_only = True)\nwarp_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:06.873475Z","iopub.execute_input":"2024-08-05T12:20:06.873916Z","iopub.status.idle":"2024-08-05T12:20:10.460190Z","shell.execute_reply.started":"2024-08-05T12:20:06.873874Z","shell.execute_reply":"2024-08-05T12:20:10.459285Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2SdpaAttention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def generate(model, idx):\n    idx = idx.to(device)\n    \n    # TODO check each param \n    output = model.generate(idx, max_length = 50, pad_token_id=50256, num_return_sequences = 1, return_dict_in_generate=True, output_scores=True, temperature = temperature)\n    output_ids = output['sequences']\n    generation = policy_tokenizer.batch_decode(output_ids)\n    \n    return output_ids.clone(), generation","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:10.461758Z","iopub.execute_input":"2024-08-05T12:20:10.462026Z","iopub.status.idle":"2024-08-05T12:20:10.467327Z","shell.execute_reply.started":"2024-08-05T12:20:10.462004Z","shell.execute_reply":"2024-08-05T12:20:10.466370Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def reward_fn_sentiment_imdb(gen_sample):\n    with torch.no_grad():\n        tokens = reward_tokenizer(gen_sample, return_tensors='pt', padding=True, truncation=True)['input_ids'].to(device)\n        logits = reward_model(tokens).logits\n        positive_cls = logits.softmax(dim=-1)[:, 1] # TODO CHECK that pos = 1 and neg = 0\n    return positive_cls.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:10.468279Z","iopub.execute_input":"2024-08-05T12:20:10.468636Z","iopub.status.idle":"2024-08-05T12:20:10.484371Z","shell.execute_reply.started":"2024-08-05T12:20:10.468604Z","shell.execute_reply":"2024-08-05T12:20:10.483442Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"sft_tokens = sft_model.generate(tokenized, max_length=50)\nsft_decoded = policy_tokenizer.batch_decode(sft_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:10.485531Z","iopub.execute_input":"2024-08-05T12:20:10.486143Z","iopub.status.idle":"2024-08-05T12:20:12.096516Z","shell.execute_reply.started":"2024-08-05T12:20:10.486083Z","shell.execute_reply":"2024-08-05T12:20:12.095484Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"}]},{"cell_type":"code","source":"warp_tokens = warp_model.generate(tokenized, max_length=50)\nward_decoded = policy_tokenizer.batch_decode(warp_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:12.097862Z","iopub.execute_input":"2024-08-05T12:20:12.098348Z","iopub.status.idle":"2024-08-05T12:20:12.668527Z","shell.execute_reply.started":"2024-08-05T12:20:12.098322Z","shell.execute_reply":"2024-08-05T12:20:12.667423Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"}]},{"cell_type":"code","source":"reward_fn_sentiment_imdb(ward_decoded).mean()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:12.669805Z","iopub.execute_input":"2024-08-05T12:20:12.672558Z","iopub.status.idle":"2024-08-05T12:20:13.346984Z","shell.execute_reply.started":"2024-08-05T12:20:12.672527Z","shell.execute_reply":"2024-08-05T12:20:13.346026Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor(0.6088, device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"reward_fn_sentiment_imdb(sft_decoded).mean()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:13.348167Z","iopub.execute_input":"2024-08-05T12:20:13.348477Z","iopub.status.idle":"2024-08-05T12:20:14.012045Z","shell.execute_reply.started":"2024-08-05T12:20:13.348451Z","shell.execute_reply":"2024-08-05T12:20:14.011105Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor(0.5525, device='cuda:0')"},"metadata":{}}]},{"cell_type":"code","source":"def get_kl(training_logits, ref_logits, first_n):\n    # TODO write log_softmax\n    \n    training_logprobs = training_logits.log_softmax(-1)\n    ref_logprobs = ref_logits.log_softmax(-1)\n\n    probs = training_logprobs.exp()\n    \n    kl = (probs * (training_logprobs - ref_logprobs))[:, first_n:-1].sum(-1)\n    return kl.mean()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:14.013249Z","iopub.execute_input":"2024-08-05T12:20:14.013545Z","iopub.status.idle":"2024-08-05T12:20:14.019157Z","shell.execute_reply.started":"2024-08-05T12:20:14.013520Z","shell.execute_reply":"2024-08-05T12:20:14.018259Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"warp_logits = warp_model(warp_tokens).logits.detach()\nref_logits = sft_model(warp_tokens).logits.detach()","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:14.020398Z","iopub.execute_input":"2024-08-05T12:20:14.020675Z","iopub.status.idle":"2024-08-05T12:20:15.144306Z","shell.execute_reply.started":"2024-08-05T12:20:14.020651Z","shell.execute_reply":"2024-08-05T12:20:15.143518Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"get_kl(warp_logits, ref_logits, first_n)","metadata":{"execution":{"iopub.status.busy":"2024-08-05T12:20:20.137776Z","iopub.execute_input":"2024-08-05T12:20:20.138384Z","iopub.status.idle":"2024-08-05T12:20:20.176319Z","shell.execute_reply.started":"2024-08-05T12:20:20.138347Z","shell.execute_reply":"2024-08-05T12:20:20.175428Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"tensor(0.0370, device='cuda:0')"},"metadata":{}}]}]}